<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Itzik Malkiel</title>
    <meta name="author" content="Itzik Malkiel">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon"
          href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">

    <style>
        .circle {
            border-radius: 50%;
            overflow: hidden;
        }
    </style>
</head>

</html>
<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <h1 style="text-align:center">Itzik Malkiel - TEMP</h1>
                        <p>abstract</p>
                        <p>At XXX I've worked on</p>
                        <p style="text-align:center">
                            <a href="mailto:itzik.malkiel@gmail.com">Email</a> &nbsp;/&nbsp;
                            <a href="data/my-CV.pdf">CV</a> &nbsp;/&nbsp;
<!--                            <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;-->
                            <a href="https://scholar.google.co.il/citations?user=4VOu-tUAAAAJ&hl=en">Google Scholar</a>
                            &nbsp;/&nbsp;
                            <!--<a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                            <a href="https://github.com/ItzikMalkiel">Github</a>
                        </p>
                    </td>
                    <div class="circle">
                        <td style="padding:2.5%;width:40%;max-width:40%">
                            <a href="images/itzikmalkiel.jpg">
                                <img style="border-radius: 50%; width: 200px; height: 200px;" alt="profile photo" src="images/profilePic.jpg"
                                     class="hoverZoomLink">
                            </a>
                        </td>
                    </div>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:50%;vertical-align:middle">
                        <h2>Research</h2>
                        <p>research interests. Representative papers are <span class="highlight">highlighted</span>.</p>
                    </td>
                    <td style="padding:20px;width:50%;vertical-align:middle">
                        <h3>* denotes equal contribution.</h3>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:40px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/metricFMRI4.png' width="180">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://openreview.net/pdf?id=W9qI8DwoUFF">
                            <h3>Pre-Training Transformers for Fingerprinting to Improve Stress Prediction in fMRI</h3>
                        </a>
                        <p>G Rosenman*, <strong>I Malkiel*</strong>, A Greental, T Hendler, L Wolf</p>
                        <p><em>Medical Imaging with Deep Learning (MIDL), 2023. Long paper.</em></p>
                        <p><a href="https://github.com/GonyRosenman/MetricfMRI">github</a></p>
                        <p>We introduce MetricFMRI, a Transformer-based model and a pre-training procedure for
                            fingerprinting on fMRI data, to enhance the accuracy of stress predictions.</p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/gpt-calls2.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <h3>GPT-Distilled Calls Segmentation and Tagging for Conversation Intelligence in Dynamics
                            365 Sales</h3>
                        <p><strong>I Malkiel*</strong>, U Alon*, Y Yehuda, S Keren, N Koenigstein</p>
                        <p><em>Machine Learning, AI and Data Science Conference (MLADS), 2023.</em></p>
                        <p><em>Microsoft Journal of Applied Research (MSJAR), 2023.</em></p>
                        <p>We propose a novel method, we call GPT-distilled Calls Segmentation and Tagging (GPT-CST),
                            for efficient and accurate call segmentation and topic extraction.</p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/convergence2.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://mlads2022.azurewebsites.net/pdf/recommendations.pdf">
                            <h3>Intelligent Recommendations: Self-Supervised Triplet Training for Textual Item
                                Similarity</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, D Ginzburg, O Barkan, A Caciularu, Y Weill, O Katz, N Koenigstein
                        </p>
                        <p><em>Machine Learning, AI and Data Science Conference (MLADS), 2022.</em></p>
                        <p><em>Microsoft Journal of Applied Research (MSJAR), 2022.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/IntelligentRecommendations">github</a></p>
                        <p>We propose a self-supervised triplet training approach for intelligent recommendations based
                            on textual item similarity.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/tff.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://openreview.net/pdf?id=5vN1d_MZp2U">
                            <h3>Self-Supervised Transformers for fMRI representation</h3>
                        </a>
                        <p><strong>I Malkiel*</strong>, G Rosenman*, L Wolf, T Hendler</p>
                        <p><em>Medical Imaging with Deep Learning (MIDL), 2022. Long paper.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/SelfSupervisedTransformers">github</a></p>
                        <p>We introduce self-supervised transformers for fMRI representation to enhance the
                            understanding of brain activity.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/metricBERT2.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/document/9414229">
                            <h3>MetricBERT: Text Representation Learning Via Self-Supervised Triplet Training</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, D Ginzburg, O Barkan, A Caciularu, J Weill, N Koenigstein</p>
                        <p><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),
                            2022.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/MetricBERT">github</a></p>
                        <p>We present MetricBERT, a self-supervised triplet training method for text representation
                            learning.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/bti.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://dl.acm.org/doi/abs/10.1145/3442381.3449920">
                            <h3>Interpreting BERT-based Text Similarity via Activation and Saliency Maps</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, D Ginzburg, O Barkan, A Caciularu, J Weill, N Koenigstein</p>
                        <p><em>The Web Conference (WWW), 2022. Long paper.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/BERTInterpretation">github</a></p>
                        <p>We propose a method for interpreting BERT-based text similarity using activation and saliency
                            maps.</p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/mtadam.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://www.aclweb.org/anthology/2021.emnlp-long.296">
                            <h3>MTAdam: Automatic Balancing of Multiple Training Loss Terms</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, L Wolf</p>
                        <p><em>Empirical Methods in Natural Language Processing (EMNLP), 2021. Long paper.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/MTAdam">github</a></p>
                        <p>We propose MTAdam, a method for automatic balancing of multiple training loss terms in
                            optimization.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/hate_speech.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://www.aclweb.org/anthology/2021.emnlp-short.187">
                            <h3>Caption Enriched Samples for Improving Hateful Memes Detection</h3>
                        </a>
                        <p>E Blaier*, <strong>I Malkiel*</strong>, L Wolf</p>
                        <p><em>Empirical Methods in Natural Language Processing (EMNLP), 2021. Short paper.</em></p>
                        <p><a href="https://github.com/EyalBlaier/CaptionEnrichedHatefulMemes">github</a></p>
                        <p>We propose using caption enriched samples to enhance the detection of hateful memes.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/gam.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://dl.acm.org/doi/10.1145/3459637.3482284">
                            <h3>GAM: Explainable Visual Similarity and Classification via Gradient Activation Maps</h3>
                        </a>
                        <p>O Barkan, O Armstrong, A Hertz, A Caciularu, O Katz, <strong>I Malkiel</strong>, N
                            Koenigstein</p>
                        <p><em>The 30th ACM International Conference on Information and Knowledge Management (CIKM),
                            2021. Long paper.</em></p>
                        <p><a href="https://github.com/OpenXAIProject/GAM">github</a></p>
                        <p>We introduce GAM, a method for explainable visual similarity and classification using
                            gradient activation maps.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/gradsam.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://dl.acm.org/doi/10.1145/3459637.3482093">
                            <h3>Grad-SAM: Explaining Transformers via Gradient Self-Attention Maps</h3>
                        </a>
                        <p>O Barkan, E Hauon, A Caciularu, O Katz, <strong>I Malkiel</strong>, O Armstrong, N
                            Koenigstein</p>
                        <p><em>The 30th ACM International Conference on Information and Knowledge Management (CIKM),
                            2021. Short paper.</em></p>
                        <p><a href="https://github.com/OpenXAIProject/GradSAM">github</a></p>
                        <p>We propose Grad-SAM, a method for explaining transformers using gradient self-attention
                            maps.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:50px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/vbnet.png' width="180">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://dl.acm.org/doi/10.1145/3459637.3482210">
                            <h3>Representation Learning via Variational Bayesian Networks</h3>
                        </a>
                        <p>O Barkan, A Caciularu, I Rejwan, O Katz, J Weill, <strong>I Malkiel</strong>, N Koenigstein
                        </p>
                        <p><em>The 30th ACM International Conference on Information and Knowledge Management (CIKM),
                            2021. Long paper.</em></p>
                        <p><a href="https://github.com/OpenXAIProject/VariationalBayesianNetworks">github</a></p>
                        <p>We present a representation learning method based on variational Bayesian networks.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/sdr.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://www.aclweb.org/anthology/2021.findings-acl.211">
                            <h3>Self-Supervised Document Similarity Ranking via Contextualized Language Models and
                                Hierarchical Inference</h3>
                        </a>
                        <p>D Ginzburg*, <strong>I Malkiel*</strong>, O Barkan, A Caciularu, N Koenigstein</p>
                        <p><em>The Association for Computational Linguistics (ACL): Findings, 2021. Long paper.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/DocSimRanking">github</a></p>
                        <p>We propose a self-supervised method for document similarity ranking using contextualized
                            language models and hierarchical inference.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/spectra2pix.png' width="280">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://www.osapublishing.org/ol/abstract.cfm?uri=ol-46-5-1039">
                            <h3>Inverse design of unparametrized nanostructures by generating images from spectra</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, M Mrejen, L Wolf, H Suchowski</p>
                        <p><em>Optics Letters, 2021.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/InverseDesignNanostructures">github</a></p>
                        <p>We propose a method for inverse design of unparametrized nanostructures by generating images
                            from spectra.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/cgan-7.png' width="270">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/document/9403885">
                            <h3>Adaptive Gradient Balancing for Undersampled MRI Reconstruction and Image-to-Image
                                Translation</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, S Ahn, V Taviani, A Menini, L Wolf, CJ Hardy</p>
                        <p><em>International Conference on Computational Photography (ICCP), 2021.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/AdaptiveGradientBalancing">github</a></p>
                        <p>We propose adaptive gradient balancing for improving undersampled MRI reconstruction and
                            image-to-image translation tasks.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/mml.png' width="280">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://www.aclweb.org/anthology/2021.eacl-long.210">
                            <h3>Maximal Multiverse Learning for Promoting Cross-Task Generalization of Fine-Tuned
                                Language Models</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, L Wolf</p>
                        <p><em>European Chapter of the Association for Computational Linguistics (EACL), 2021. Long
                            paper.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/MaximalMultiverseLearning">github</a></p>
                        <p>We propose maximal multiverse learning to promote cross-task generalization of fine-tuned
                            language models.</p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/icdm.png' width="250">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/document/9338460">
                            <h3>Cold Item Recommendations via Hierarchical Item2vec</h3>
                        </a>
                        <p>O Barkan, A Caciularu, I Rejwan, O Katz, J Weill, <strong>I Malkiel</strong>, N Koenigstein
                        </p>
                        <p><em>IEEE International Conference on Data Mining (ICDM), 912-917, 2020.</em></p>
                        <p><a href="https://github.com/OpenXAIProject/HierarchicalItem2vec">github</a></p>
                        <p>We propose hierarchical Item2vec for cold item recommendations.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/recobert.png' width="280">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.173">
                            <h3>RecoBERT: A Catalog Language Model for Text-Based Recommendations</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, O Barkan, A Caciularu, N Razin, O Katz, N Koenigstein</p>
                        <p><em>Empirical Methods in Natural Language Processing (EMNLP): Findings, 2020. Long
                            paper.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/RecoBERT">github</a></p>
                        <p>We introduce RecoBERT, a catalog language model for text-based recommendations.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/icassp_fabrication_full_v3.png' width="270">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/document/9191624">
                            <h3>Retrieving Nanostructure Images from Spectra</h3>
                        </a>
                        <p>M Mrejen*, <strong>I Malkiel*</strong>, L Wolf, H Suchowski</p>
                        <p><em>Conference on Lasers and Electro-Optics (CLEO), 2020.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/RetrievingNanostructureImages">github</a></p>
                        <p>We propose a method for retrieving nanostructure images from spectra.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:50px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/aaai.png' width="160">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5832">
                            <h3>Scalable Attentive Sentence Pair Modeling via Distilled Sentence Embedding</h3>
                        </a>
                        <p>O Barkan, N Razin, <strong>I Malkiel</strong>, O Katz, A Caciularu, N Koenigstein</p>
                        <p><em>AAAI Conference on Artificial Intelligence (AAAI), 2020.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/ScalableAttentiveSentencePairModeling">github</a></p>
                        <p>We propose scalable attentive sentence pair modeling using distilled sentence embedding.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/cambridge.png' width="270">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://www.cambridge.org/core/journals/mrs-bulletin/article/machine-learning-for-nanophotonics/B1666C85EA7B7CC0A84EADF9B4DF4AA9">
                            <h3>Machine Learning for Nanophotonics</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, M Mrejen, L Wolf, H Suchowski</p>
                        <p><em>MRS Bulletin, 45(3), 221-229. 2020.</em></p>
                        <p><a href="https://doi.org/10.1557/mrs.2020.44">doi</a></p>
                        <p>We review the applications of machine learning in the field of nanophotonics.</p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/cleo2019.png' width="270">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://opg.optica.org/viewmedia.cfm?uri=CLEO_QELS-2019-FTu4C.3&seq=0">
                            <h3>Deep Learning for Design and Retrieval of Plasmonic Nanostructures</h3>
                        </a>
                        <p>M Mrejen*, <strong>I Malkiel*</strong>, A Nagler, U Arieli, L Wolf, H Suchowski</p>
                        <p><em>Conference on Lasers and Electro-Optics (CLEO), 2019.</em></p>
                        <p><em>15th International Work-Conference on Artificial Neural Networks (IWANN), 2019.</em></p>
                        <p><a href="https://github.com/IrisMalkiel/DeepLearningPlasmonicNanostructures">github</a></p>
                        <p>We utilize deep learning for the design and retrieval of plasmonic nanostructures.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/mri_motion.png' width="270">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://cds.ismrm.org/protected/19MProceedings/PDFfiles/4438.html">
                            <h3>Towards Motion-Robust MRI ‚Äì Autonomous Motion Timing and Correction during MR Scanning
                                using Multi-Coil Data and a Deep-Learning Neural Network</h3>
                        </a>
                        <p>R Brada, M Rotman, R Wein, S Ahn, <strong>I Malkiel</strong>, CJ Hardy</p>
                        <p><em>International Society for Magnetic Resonance in Medicine (ISMRM), 2019.</em></p>
                        <p>We propose a method for motion-robust MRI using deep learning and multi-coil data.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/Ablation%20FID%201000%20epochs.png' width="270">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://cds.ismrm.org/protected/19MProceedings/PDFfiles/0474.html">
                            <h3>Leveraging Conditional GANs with Adaptive Loss Balancing for MRI Sparse
                                Reconstruction</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, S Ahn, V Taviani, A Menini, Z Slavens, CJ Hardy</p>
                        <p><em>International Society for Magnetic Resonance in Medicine (ISMRM), 2019.</em></p>
                        <p>We leverage conditional GANs with adaptive loss balancing for MRI sparse reconstruction.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/residual-network-MRI.png' width="160">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://cds.ismrm.org/protected/18MLearning/files/abstracts/02041.html">
                            <h3>Residual Network with Null Data Consistency for Sparse MRI Reconstruction</h3>
                        </a>
                        <p>CJ Hardy, <strong>I Malkiel</strong>, S Ahn, V Taviani, A Menini, Z Slavens</p>
                        <p><em>ISMRM Workshop on Machine Learning, 2018.</em></p>
                        <p>We propose a residual network with null data consistency for sparse MRI reconstruction.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/ISMRM2018-004657_Fig1.png' width="270">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://cds.ismrm.org/protected/18MProceedings/PDFfiles/0617.html">
                            <h3>Improving Variable-Density Single-Shot Fast Spin Echo with Deep-Learning Reconstruction
                                Using Variational Networks</h3>
                        </a>
                        <p>F Chen, V Taviani, <strong>I Malkiel</strong>, JY Cheng, J Shaikh, S Chang, CJ Hardy, JM
                            Pauly, SS Vasanawala</p>
                        <p><em>International Society for Magnetic Resonance in Medicine (ISMRM), 2018.</em></p>
                        <p>We improve variable-density single-shot fast spin echo using deep-learning reconstruction and
                            variational networks.</p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:0px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/dcinet.png' width="270">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://cds.ismrm.org/protected/18MProceedings/PDFfiles/3363.html">
                            <h3>Densely Connected Iterative Network for Sparse MRI Reconstruction</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, S Ahn, Z Slavens, V Taviani, CJ Hardy</p>
                        <p><em>International Society for Magnetic Resonance in Medicine (ISMRM), 2018.</em></p>
                        <p>We propose a densely connected iterative network for sparse MRI reconstruction.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:40px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/radio.png' width="200">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://pubs.rsna.org/doi/10.1148/radiol.2018180638">
                            <h3>Variable-Density Single-Shot Fast Spin Echo MR Imaging with Deep-Learning Reconstruction
                                Using Variational Networks</h3>
                        </a>
                        <p>F Chen, V Taviani, <strong>I Malkiel</strong>, JY Cheng, J Shaikh, S Chang, CJ Hardy, JM
                            Pauly, S Vasanawala</p>
                        <p><em>Radiology, 2018.</em></p>
                        <p>We propose a variable-density single-shot fast spin echo MR imaging with deep-learning
                            reconstruction using variational networks.</p>
                    </td>
                </tr>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/light.png' width="230">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://www.nature.com/articles/s41377-018-0060-7">
                            <h3>Plasmonic Nano-structures Design and Characterization via Deep Learning</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, M Mrejen, A Nagler, U Arieli, L Wolf, H Suchowski</p>
                        <p><em>Light: Science & Applications, 2018.</em></p>
                        <p>We showcase a bi-directional Deep Neural Network for solving the inverse design problem in nanophotonics, enabling rapid design and characterization of optical elements, and compare the proposed model with various alternative methods such as Genetic Algorithms.</p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <div class="one">
                            <img src='images/som7.png' width="230">
                        </div>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/document/8368462">
                            <h3>Deep Learning for the Design of Nano-photonic Structures</h3>
                        </a>
                        <p><strong>I Malkiel</strong>, A Nagler, M Mrejen, U Arieli, L Wolf, H Suchowski</p>
                        <p><em>International Conference on Computational Photography (ICCP), 2018.</em></p>
                        <p><a href="https://github.com/ItzikMalkiel/DeepNanoDesign">github</a></p>
                        <p>We present a novel Deep Learning approach to predict nanostructure geometry from far-field response, offering a solution to the challenging inverse problem and enabling customizable designs for optical applications including sensing, imaging, and cancer thermotherapy.</p>

                    </td>
                </tr>


                </tbody>
            </table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <h2>Misc</h2>
                    </td>
                </tr>
                </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
                <tbody>
                <tr>
                    <td style="padding:20px;width:35%;vertical-align:middle">
                        <img src="images/cvf.jpg">
                    </td>
                    <td width="75%" valign="center">
                        <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                        <br>
                        <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee
                            Member, CVPR 2021</a>
                        <br>
                        <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                        <br>
                        <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source
                            code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes
                            analytics tags that you do not want on your own website &mdash; use the GitHub code instead.
                            Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a
                                href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
    </tbody>
</table>
</body>
</html>
